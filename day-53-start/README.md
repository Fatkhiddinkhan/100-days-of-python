### Day 53: Scraping Zillow Clone & Auto-Filling Google Forms ğŸ ğŸ“‹

Today marks **Day 53** of my 100 Days of Code journey. In this project, I focused on scraping a Zillow-like website for property information and then automatically submitting the data into a Google Form. This exercise helped me deepen my understanding of web scraping and form automation using Python.

#### Whatâ€™s Going On Here?

1. **ZillowScraper** ğŸ•¸ï¸ğŸ”
    - **Uses the `requests` library and BeautifulSoup** to fetch and parse HTML from a Zillow-clone site.
    - **Extracts property links, prices, and addresses**, gathering essential information about each listing.

2. **GoogleSheetBot** ğŸ“„ğŸ¤–
    - **Uses Selenium** to open a Google Form in Chrome, fill out each input field for address, price, and property link, then submit the form.
    - **Repeats for all properties scraped**, resulting in a neatly filled spreadsheet on the backend of the Google Form.

#### Note

Iâ€™m grateful for all I learned today. Creating a small pipeline to scrape data from one site and fill a form on another was surprisingly handy and reinforced my skills in web scraping and automation. I'm happy with the progress and motivated to keep ironing out any bugs and refining my skills. Hereâ€™s to tomorrowâ€™s adventures! ğŸš€âœ¨

Stay tuned for more updates. ğŸŒŸ